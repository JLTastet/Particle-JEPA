{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Random Wedge Sampler Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' (dataloaders.py, line 47)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/.conda/envs/jepa/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[1], line 18\u001b[0m\n    from jepa.modules import JEPA\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/global/cfs/cdirs/m3443/usr/dtmurnane/Side_Work/Particle-JEPA/jepa/modules/__init__.py:2\u001b[0m\n    from .models.jepa import JEPA\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m/global/cfs/cdirs/m3443/usr/dtmurnane/Side_Work/Particle-JEPA/jepa/modules/models/jepa.py:17\u001b[0;36m\n\u001b[0;31m    from toytrack.dataloaders import TracksDataset\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/toytrack/dataloaders.py:47\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, config: Dict, transforms: Optional[Union[Callable, List[Callable]]]] = None):\u001b[0m\n\u001b[0m                                                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m closing parenthesis ']' does not match opening parenthesis '('\n"
     ]
    }
   ],
   "source": [
    "# use autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# import lightning trainer\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "# imports\n",
    "from jepa.modules import JEPA\n",
    "\n",
    "from toytrack.dataloaders import TracksDataset\n",
    "from jepa.utils import WedgePatchify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wedgify Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of jepa.modules.models.jepa failed: Traceback (most recent call last):\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/jepa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/jepa/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/global/homes/d/danieltm/.conda/envs/jepa/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1017, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 947, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/global/cfs/cdirs/m3443/usr/dtmurnane/Side_Work/Particle-JEPA/jepa/modules/models/jepa.py\", line 253\n",
      "    print(f\"Batch shapes: x={x.shape}, mask={mask.shape}, \n",
      "          ^\n",
      "SyntaxError: unterminated string literal (detected at line 253)\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "config = yaml.load(open('configs/12_testing.yaml'), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchify = WedgePatchify(phi_range=np.pi / 4, radius_midpoint = (config[\"dataset_args\"][\"detector\"][\"max_radius\"] + config[\"dataset_args\"][\"detector\"][\"min_radius\"]) / 2)\n",
    "\n",
    "dataset = TracksDataset(config[\"dataset_args\"], transform=patchify)\n",
    "dataloader = DataLoader(dataset, batch_size=3, num_workers=0, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected phi: 0.8861\n",
      "Phi range: [0.4934, 1.2788]\n",
      "Hits in phi mask: 6\n",
      "Hits in inner mask: 28\n",
      "Hits in outer mask: 28\n",
      "Hits in context mask: 2\n",
      "Hits in target mask: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample in dataset:\n",
    "    inner_x = sample[\"x\"][sample[\"context_mask\"]]\n",
    "    outer_x = sample[\"x\"][sample[\"target_mask\"]]\n",
    "\n",
    "    plt.scatter(sample[\"x\"][:, 0], sample[\"x\"][:, 1], color=\"black\", alpha=0.5)\n",
    "    plt.scatter(inner_x[:, 0], inner_x[:, 1], color=\"blue\")\n",
    "    plt.scatter(outer_x[:, 0], outer_x[:, 1], color=\"red\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected phi: -2.4528\n",
      "Phi range: [-2.8455, -2.0601]\n",
      "Hits in phi mask: 15\n",
      "Hits in inner mask: 36\n",
      "Hits in outer mask: 36\n",
      "Hits in context mask: 8\n",
      "Hits in target mask: 7\n",
      "Selected phi: -2.1321\n",
      "Phi range: [-2.5248, -1.7394]\n",
      "Hits in phi mask: 14\n",
      "Hits in inner mask: 20\n",
      "Hits in outer mask: 20\n",
      "Hits in context mask: 8\n",
      "Hits in target mask: 6\n",
      "Selected phi: -3.0843\n",
      "Phi range: [-3.4770, -2.6916]\n",
      "Hits in phi mask: 5\n",
      "Hits in inner mask: 32\n",
      "Hits in outer mask: 32\n",
      "Hits in context mask: 3\n",
      "Hits in target mask: 2\n",
      "{'x': tensor([[[ 0.1405, -0.4798],\n",
      "         [ 0.2518, -0.8193],\n",
      "         [ 0.4103, -1.1429],\n",
      "         [ 0.6159, -1.4457],\n",
      "         [ 0.8682, -1.7221],\n",
      "         [ 1.1668, -1.9655],\n",
      "         [ 1.5113, -2.1681],\n",
      "         [ 1.9011, -2.3207],\n",
      "         [ 0.3913,  0.3112],\n",
      "         [ 0.5930,  0.6189],\n",
      "         [ 0.7500,  0.9550],\n",
      "         [ 0.8583,  1.3163],\n",
      "         [ 0.9132,  1.6986],\n",
      "         [ 0.9093,  2.0970],\n",
      "         [ 0.8401,  2.5058],\n",
      "         [ 0.6974,  2.9178],\n",
      "         [-0.0633,  0.4960],\n",
      "         [-0.1698,  0.8402],\n",
      "         [-0.3260,  1.1697],\n",
      "         [-0.5318,  1.4787],\n",
      "         [-0.7868,  1.7608],\n",
      "         [-1.0909,  2.0086],\n",
      "         [-1.4439,  2.2136],\n",
      "         [-1.8453,  2.3653],\n",
      "         [-0.1721,  0.4695],\n",
      "         [-0.3781,  0.7692],\n",
      "         [-0.6277,  1.0395],\n",
      "         [-0.9190,  1.2747],\n",
      "         [-1.2498,  1.4688],\n",
      "         [-1.6177,  1.6147],\n",
      "         [-2.0199,  1.7043],\n",
      "         [-2.4529,  1.7273],\n",
      "         [-0.4445,  0.2289],\n",
      "         [-0.7656,  0.3854],\n",
      "         [-1.0632,  0.5866],\n",
      "         [-1.3333,  0.8317],\n",
      "         [-1.5702,  1.1197],\n",
      "         [-1.7675,  1.4493],\n",
      "         [-1.9173,  1.8189],\n",
      "         [-2.0103,  2.2268],\n",
      "         [-0.2803, -0.4141],\n",
      "         [-0.5363, -0.6686],\n",
      "         [-0.8289, -0.8873],\n",
      "         [-1.1552, -1.0654],\n",
      "         [-1.5120, -1.1972],\n",
      "         [-1.8958, -1.2769],\n",
      "         [-2.3026, -1.2973],\n",
      "         [-2.7273, -1.2498],\n",
      "         [ 0.2176, -0.4502],\n",
      "         [ 0.3512, -0.7819],\n",
      "         [ 0.4383, -1.1324],\n",
      "         [ 0.4757, -1.4977],\n",
      "         [ 0.4600, -1.8729],\n",
      "         [ 0.3870, -2.2527],\n",
      "         [ 0.2521, -2.6308],\n",
      "         [ 0.0495, -2.9996],\n",
      "         [ 0.4747,  0.1571],\n",
      "         [ 0.8192,  0.2521],\n",
      "         [ 1.1773,  0.2975],\n",
      "         [ 1.5444,  0.2904],\n",
      "         [ 1.9151,  0.2277],\n",
      "         [ 2.2833,  0.1057],\n",
      "         [ 2.6416, -0.0799],\n",
      "         [ 2.9813, -0.3345],\n",
      "         [-0.3748, -0.3309],\n",
      "         [-0.6617, -0.5448],\n",
      "         [-0.9798, -0.7173],\n",
      "         [-1.3255, -0.8441],\n",
      "         [-1.6949, -0.9201],\n",
      "         [-2.0837, -0.9395],\n",
      "         [-2.4865, -0.8956],\n",
      "         [-2.8968, -0.7802]],\n",
      "\n",
      "        [[ 0.4998,  0.0137],\n",
      "         [ 0.8549,  0.0618],\n",
      "         [ 1.2038,  0.1596],\n",
      "         [ 1.5410,  0.3078],\n",
      "         [ 1.8607,  0.5073],\n",
      "         [ 2.1561,  0.7587],\n",
      "         [ 2.4196,  1.0632],\n",
      "         [ 2.6416,  1.4219],\n",
      "         [ 0.2370, -0.4402],\n",
      "         [ 0.3576, -0.7790],\n",
      "         [ 0.4299, -1.1356],\n",
      "         [ 0.4506, -1.5054],\n",
      "         [ 0.4162, -1.8831],\n",
      "         [ 0.3225, -2.2628],\n",
      "         [ 0.1648, -2.6377],\n",
      "         [-0.0629, -2.9993],\n",
      "         [-0.2063, -0.4555],\n",
      "         [-0.4563, -0.7256],\n",
      "         [-0.7446, -0.9592],\n",
      "         [-1.0690, -1.1518],\n",
      "         [-1.4265, -1.2978],\n",
      "         [-1.8139, -1.3908],\n",
      "         [-2.2270, -1.4231],\n",
      "         [-2.6610, -1.3853],\n",
      "         [-0.4918,  0.0905],\n",
      "         [-0.8297,  0.2151],\n",
      "         [-1.1507,  0.3878],\n",
      "         [-1.4491,  0.6079],\n",
      "         [-1.7186,  0.8751],\n",
      "         [-1.9524,  1.1886],\n",
      "         [-2.1423,  1.5477],\n",
      "         [-2.2785,  1.9515],\n",
      "         [-0.1313, -0.4825],\n",
      "         [-0.2487, -0.8203],\n",
      "         [-0.4144, -1.1414],\n",
      "         [-0.6279, -1.4405],\n",
      "         [-0.8889, -1.7115],\n",
      "         [-1.1967, -1.9474],\n",
      "         [-1.5508, -2.1400],\n",
      "         [-1.9506, -2.2793],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.4996, -0.0190],\n",
      "         [ 0.8571,  0.0119],\n",
      "         [ 1.2107,  0.0935],\n",
      "         [ 1.5550,  0.2268],\n",
      "         [ 1.8838,  0.4130],\n",
      "         [ 2.1904,  0.6531],\n",
      "         [ 2.4667,  0.9487],\n",
      "         [ 2.7030,  1.3015],\n",
      "         [-0.2800, -0.4143],\n",
      "         [-0.4276, -0.7429],\n",
      "         [-0.5278, -1.0936],\n",
      "         [-0.5766, -1.4618],\n",
      "         [-0.5700, -1.8424],\n",
      "         [-0.5030, -2.2297],\n",
      "         [-0.3701, -2.6168],\n",
      "         [-0.1644, -2.9955],\n",
      "         [-0.3384, -0.3681],\n",
      "         [-0.5780, -0.6330],\n",
      "         [-0.7803, -0.9304],\n",
      "         [-0.9416, -1.2581],\n",
      "         [-1.0574, -1.6129],\n",
      "         [-1.1222, -1.9913],\n",
      "         [-1.1298, -2.3892],\n",
      "         [-1.0725, -2.8017],\n",
      "         [ 0.3384, -0.3681],\n",
      "         [ 0.5845, -0.6270],\n",
      "         [ 0.8661, -0.8511],\n",
      "         [ 1.1812, -1.0364],\n",
      "         [ 1.5270, -1.1781],\n",
      "         [ 1.9002, -1.2703],\n",
      "         [ 2.2974, -1.3064],\n",
      "         [ 2.7140, -1.2783],\n",
      "         [-0.4471, -0.2239],\n",
      "         [-0.7977, -0.3135],\n",
      "         [-1.1621, -0.3522],\n",
      "         [-1.5349, -0.3369],\n",
      "         [-1.9104, -0.2643],\n",
      "         [-2.2820, -0.1308],\n",
      "         [-2.6420,  0.0681],\n",
      "         [-2.9809,  0.3380],\n",
      "         [ 0.3864, -0.3174],\n",
      "         [ 0.5810, -0.6302],\n",
      "         [ 0.7301, -0.9703],\n",
      "         [ 0.8300, -1.3343],\n",
      "         [ 0.8762, -1.7180],\n",
      "         [ 0.8634, -2.1164],\n",
      "         [ 0.7850, -2.5236],\n",
      "         [ 0.6335, -2.9323],\n",
      "         [-0.1195, -0.4855],\n",
      "         [-0.2745, -0.8120],\n",
      "         [-0.4768, -1.1168],\n",
      "         [-0.7251, -1.3941],\n",
      "         [-1.0184, -1.6377],\n",
      "         [-1.3555, -1.8404],\n",
      "         [-1.7347, -1.9938],\n",
      "         [-2.1544, -2.0877],\n",
      "         [-0.3376,  0.3688],\n",
      "         [-0.4734,  0.7146],\n",
      "         [-0.5584,  1.0783],\n",
      "         [-0.5900,  1.4564],\n",
      "         [-0.5646,  1.8441],\n",
      "         [-0.4777,  2.2352],\n",
      "         [-0.3240,  2.6229],\n",
      "         [-0.0971,  2.9984],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]]]), 'mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "          True,  True,  True,  True, False, False, False, False, False, False,\n",
      "         False, False]]), 'pids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "         5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8],\n",
      "        [2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "         7, 7, 7, 7, 7, 7, 7, 7, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "         5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0]]), 'event': [Event(particles=         vx        vy   vz        pt      pphi  dimension  charge        d0  \\\n",
      "0  0.066703 -0.005373  0.0  2.582790 -3.080330          2       1  0.066347   \n",
      "1  0.069121 -0.038503  0.0  2.573629 -0.836963          2       1  0.073847   \n",
      "2 -0.019819  0.099520  0.0  2.541327  1.362599          2      -1  0.094912   \n",
      "3  0.065141  0.090805  0.0  2.587733  2.660018          2      -1  0.000485   \n",
      "4  0.000579  0.033400  0.0  2.544502  0.045415          2       1  0.000675   \n",
      "5  0.012140  0.085383  0.0  2.549875  0.363538          2       1  0.033670   \n",
      "6 -0.040153 -0.028168  0.0  2.579274 -2.497266          2      -1  0.049025   \n",
      "7 -0.092802 -0.129496  0.0  2.508549 -0.976147          2      -1  0.079238   \n",
      "8 -0.063729 -0.009946  0.0  2.509573  2.461056          2      -1  0.045856   \n",
      "\n",
      "        phi  particle_id  \n",
      "0  0.040432            0  \n",
      "1 -0.918219            1  \n",
      "2  1.444511            2  \n",
      "3  2.369998            3  \n",
      "4 -0.039666            4  \n",
      "5  0.151392            5  \n",
      "6 -2.500924            6  \n",
      "7 -1.294151            7  \n",
      "8  2.568910            8  , hits=           x         y  particle_id\n",
      "0   0.140527 -0.479846            0\n",
      "1   0.251773 -0.819332            0\n",
      "2   0.410326 -1.142857            0\n",
      "3   0.615915 -1.445696            0\n",
      "4   0.868206 -1.722093            0\n",
      "..       ...       ...          ...\n",
      "67 -1.325476 -0.844098            8\n",
      "68 -1.694949 -0.920074            8\n",
      "69 -2.083701 -0.939510            8\n",
      "70 -2.486466 -0.895645            8\n",
      "71 -2.896778 -0.780178            8\n",
      "\n",
      "[72 rows x 3 columns]), tracks=[[ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 32 33 34 35 36 37 38 40 41 42\n",
      "  43 44 45 46 16 17 18 19 20 21 22 24 25 26 27 28 29 30 48 49 50 51 52 53\n",
      "  54 56 57 58 59 60 61 62 64 65 66 67 68 69 70]\n",
      " [ 1  2  3  4  5  6  7  9 10 11 12 13 14 15 33 34 35 36 37 38 39 41 42 43\n",
      "  44 45 46 47 17 18 19 20 21 22 23 25 26 27 28 29 30 31 49 50 51 52 53 54\n",
      "  55 57 58 59 60 61 62 63 65 66 67 68 69 70 71]], detector=Detector(dimension=2), layers: [{'shape': 'cylinder', 'radius': 0.5, 'length': None}, {'shape': 'cylinder', 'radius': 0.8571428571428572, 'length': None}, {'shape': 'cylinder', 'radius': 1.2142857142857144, 'length': None}, {'shape': 'cylinder', 'radius': 1.5714285714285714, 'length': None}, {'shape': 'cylinder', 'radius': 1.9285714285714286, 'length': None}, {'shape': 'cylinder', 'radius': 2.2857142857142856, 'length': None}, {'shape': 'cylinder', 'radius': 2.642857142857143, 'length': None}, {'shape': 'cylinder', 'radius': 3.0, 'length': None}]), Event(particles=         vx        vy   vz        pt      pphi  dimension  charge        d0  \\\n",
      "0 -0.065897  0.076880  0.0  2.552994 -2.494006          2      -1  0.018813   \n",
      "1  0.113346  0.056675  0.0  2.580942  2.700820          2      -1  0.062678   \n",
      "2 -0.051286  0.036297  0.0  2.596684 -1.718167          2       1  0.032156   \n",
      "3 -0.092216  0.007526  0.0  2.586484  1.445109          2      -1  0.006915   \n",
      "4 -0.048030  0.022410  0.0  2.540451  3.079086          2      -1  0.049759   \n",
      "\n",
      "        phi  particle_id  \n",
      "0 -2.742765            0  \n",
      "1 -0.752518            1  \n",
      "2  1.558186            2  \n",
      "3  1.682196            3  \n",
      "4  3.035396            4  , hits=           x         y  particle_id\n",
      "0   0.499812  0.013709            2\n",
      "1   0.854915  0.061758            2\n",
      "2   1.203756  0.159568            2\n",
      "3   1.540986  0.307816            2\n",
      "4   1.860667  0.507255            2\n",
      "5   2.156112  0.758730            2\n",
      "6   2.419554  1.063228            2\n",
      "7   2.641609  1.421935            2\n",
      "8   0.237048 -0.440236            0\n",
      "9   0.357572 -0.778997            0\n",
      "10  0.429871 -1.135650            0\n",
      "11  0.450628 -1.505431            0\n",
      "12  0.416213 -1.883124            0\n",
      "13  0.322529 -2.262844            0\n",
      "14  0.164788 -2.637715            0\n",
      "15 -0.062852 -2.999342            0\n",
      "16 -0.206304 -0.455454            1\n",
      "17 -0.456264 -0.725615            1\n",
      "18 -0.744591 -0.959205            1\n",
      "19 -1.068982 -1.151809            1\n",
      "20 -1.426529 -1.297845            1\n",
      "21 -1.813854 -1.390836            1\n",
      "22 -2.226969 -1.423131            1\n",
      "23 -2.660981 -1.385345            1\n",
      "24 -0.491750  0.090452            3\n",
      "25 -0.829718  0.215087            3\n",
      "26 -1.150712  0.387753            3\n",
      "27 -1.449068  0.607939            3\n",
      "28 -1.718606  0.875088            3\n",
      "29 -1.952378  1.188575            3\n",
      "30 -2.142293  1.547668            3\n",
      "31 -2.278533  1.951484            3\n",
      "32 -0.131261 -0.482463            4\n",
      "33 -0.248744 -0.820256            4\n",
      "34 -0.414430 -1.141375            4\n",
      "35 -0.627946 -1.440511            4\n",
      "36 -0.888862 -1.711523            4\n",
      "37 -1.196687 -1.947416            4\n",
      "38 -1.550846 -2.139993            4\n",
      "39 -1.950640 -2.279255            4), tracks=[[ 8  9 10 11 12 13 14 16 17 18 19 20 21 22  0  1  2  3  4  5  6 24 25 26\n",
      "  27 28 29 30 32 33 34 35 36 37 38]\n",
      " [ 9 10 11 12 13 14 15 17 18 19 20 21 22 23  1  2  3  4  5  6  7 25 26 27\n",
      "  28 29 30 31 33 34 35 36 37 38 39]], detector=Detector(dimension=2), layers: [{'shape': 'cylinder', 'radius': 0.5, 'length': None}, {'shape': 'cylinder', 'radius': 0.8571428571428572, 'length': None}, {'shape': 'cylinder', 'radius': 1.2142857142857144, 'length': None}, {'shape': 'cylinder', 'radius': 1.5714285714285714, 'length': None}, {'shape': 'cylinder', 'radius': 1.9285714285714286, 'length': None}, {'shape': 'cylinder', 'radius': 2.2857142857142856, 'length': None}, {'shape': 'cylinder', 'radius': 2.642857142857143, 'length': None}, {'shape': 'cylinder', 'radius': 3.0, 'length': None}]), Event(particles=         vx        vy   vz        pt      pphi  dimension  charge        d0  \\\n",
      "0 -0.020148  0.025392  0.0  2.569182 -1.757774          2       1  0.021936   \n",
      "1  0.043618  0.000490  0.0  2.523677  2.106868          2      -1  0.019959   \n",
      "2  0.022899  0.086103  0.0  2.581550 -2.302899          2      -1  0.076693   \n",
      "3  0.020361  0.025051  0.0  2.518812  2.436095          2       1  0.000570   \n",
      "4  0.083563 -0.038127  0.0  2.598846  2.131131          2       1  0.079465   \n",
      "5  0.000051 -0.086878  0.0  2.556862  2.931812          2      -1  0.008586   \n",
      "6 -0.052889 -0.093829  0.0  2.579076  0.657249          2      -1  0.096159   \n",
      "7  0.063135  0.037632  0.0  2.587421 -2.640391          2       1  0.073459   \n",
      "\n",
      "        phi  particle_id  \n",
      "0  1.443483            0  \n",
      "1 -1.135216            1  \n",
      "2  0.707884            2  \n",
      "3 -0.624235            3  \n",
      "4 -0.901423            4  \n",
      "5  0.014202            5  \n",
      "6 -2.628788            6  \n",
      "7  0.507004            7  , hits=           x         y  particle_id\n",
      "0   0.499637 -0.019041            0\n",
      "1   0.857060  0.011882            0\n",
      "2   1.210680  0.093512            0\n",
      "3   1.554970  0.226840            0\n",
      "4   1.883840  0.412958            0\n",
      "..       ...       ...          ...\n",
      "59 -0.590047  1.456445            6\n",
      "60 -0.564607  1.844074            6\n",
      "61 -0.477674  2.235244            6\n",
      "62 -0.324006  2.622921            6\n",
      "63 -0.097140  2.998427            6\n",
      "\n",
      "[64 rows x 3 columns]), tracks=[[ 0  1  2  3  4  5  6 32 33 34 35 36 37 38 40 41 42 43 44 45 46  8  9 10\n",
      "  11 12 13 14 16 17 18 19 20 21 22 48 49 50 51 52 53 54 56 57 58 59 60 61\n",
      "  62 24 25 26 27 28 29 30]\n",
      " [ 1  2  3  4  5  6  7 33 34 35 36 37 38 39 41 42 43 44 45 46 47  9 10 11\n",
      "  12 13 14 15 17 18 19 20 21 22 23 49 50 51 52 53 54 55 57 58 59 60 61 62\n",
      "  63 25 26 27 28 29 30 31]], detector=Detector(dimension=2), layers: [{'shape': 'cylinder', 'radius': 0.5, 'length': None}, {'shape': 'cylinder', 'radius': 0.8571428571428572, 'length': None}, {'shape': 'cylinder', 'radius': 1.2142857142857144, 'length': None}, {'shape': 'cylinder', 'radius': 1.5714285714285714, 'length': None}, {'shape': 'cylinder', 'radius': 1.9285714285714286, 'length': None}, {'shape': 'cylinder', 'radius': 2.2857142857142856, 'length': None}, {'shape': 'cylinder', 'radius': 2.642857142857143, 'length': None}, {'shape': 'cylinder', 'radius': 3.0, 'length': None}])], 'context_mask': tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True,  True,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True,  True,  True, False, False,\n",
      "         False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False]]), 'target_mask': tensor([[False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False,  True,  True,\n",
      "          True, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "          True,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False]])}\n"
     ]
    }
   ],
   "source": [
    "for sample in dataloader:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/12_testing.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JEPA(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes: x=torch.Size([200, 72, 2]), mask=torch.Size([200, 72]), context_mask=torch.Size([200, 72]), target_mask=torch.Size([200, 72]), pids=torch.Size([200, 72])\n"
     ]
    }
   ],
   "source": [
    "for batch in model.train_dataloader():\n",
    "    x, mask, context_mask, target_mask, pids = model._extract_batch_data(batch)\n",
    "    model._debug_batch_shapes(x, mask, context_mask, target_mask, pids)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/12_testing.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JEPA(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/d/danieltm/.conda/envs/jepa/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /global/homes/d/danieltm/.conda/envs/jepa/lib/python ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/global/homes/d/danieltm/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type       | Params\n",
      "-------------------------------------------\n",
      "0 | encoder     | Encoder    | 73.3 K\n",
      "1 | ema_encoder | Encoder    | 73.3 K\n",
      "2 | predictor   | Sequential | 18.7 K\n",
      "-------------------------------------------\n",
      "92.0 K    Trainable params\n",
      "73.3 K    Non-trainable params\n",
      "165 K     Total params\n",
      "0.661     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Batch shapes: x=torch.Size([200, 80, 2]), mask=torch.Size([200, 80]), context_mask=torch.Size([200, 80]), target_mask=torch.Size([200, 80]), pids=torch.Size([200, 80])\n",
      "NaN detected in encoder output\n",
      "Tensor shape: torch.Size([200, 8])\n",
      "NaN locations: tensor([[51,  0],\n",
      "        [51,  1],\n",
      "        [51,  2],\n",
      "        [51,  3],\n",
      "        [51,  4],\n",
      "        [51,  5],\n",
      "        [51,  6],\n",
      "        [51,  7]], device='cuda:0')\n",
      "Tensor statistics:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "  Mean: nan\n",
      "  Std: nan\n",
      "\n",
      "Batch entry 51 containing NaN:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:0')\n",
      "x: tensor([[-0.1842, -0.4648],\n",
      "        [-0.2735, -0.8123],\n",
      "        [-0.3124, -1.1734],\n",
      "        [-0.2979, -1.5429],\n",
      "        [-0.2269, -1.9152],\n",
      "        [-0.0955, -2.2837],\n",
      "        [ 0.1006, -2.6409],\n",
      "        [ 0.3668, -2.9775],\n",
      "        [-0.4646,  0.1848],\n",
      "        [-0.8218,  0.2436],\n",
      "        [-1.1879,  0.2518],\n",
      "        [-1.5577,  0.2069],\n",
      "        [-1.9256,  0.1064],\n",
      "        [-2.2851, -0.0526],\n",
      "        [-2.6287, -0.2736],\n",
      "        [-2.9471, -0.5608],\n",
      "        [ 0.2846,  0.4111],\n",
      "        [ 0.4418,  0.7345],\n",
      "        [ 0.5524,  1.0814],\n",
      "        [ 0.6125,  1.4472],\n",
      "        [ 0.6176,  1.8270],\n",
      "        [ 0.5629,  2.2153],\n",
      "        [ 0.4426,  2.6055],\n",
      "        [ 0.2497,  2.9896],\n",
      "        [ 0.4892,  0.1032],\n",
      "        [ 0.8550,  0.0612],\n",
      "        [ 1.2138, -0.0346],\n",
      "        [ 1.5605, -0.1850],\n",
      "        [ 1.8885, -0.3911],\n",
      "        [ 2.1902, -0.6540],\n",
      "        [ 2.4564, -0.9752],\n",
      "        [ 2.6758, -1.3566],\n",
      "        [ 0.1149, -0.4866],\n",
      "        [ 0.2005, -0.8334],\n",
      "        [ 0.2373, -1.1909],\n",
      "        [ 0.2230, -1.5555],\n",
      "        [ 0.1550, -1.9223],\n",
      "        [ 0.0301, -2.2855],\n",
      "        [-0.1554, -2.6383],\n",
      "        [-0.4060, -2.9724],\n",
      "        [ 0.4132, -0.2816],\n",
      "        [ 0.6013, -0.6108],\n",
      "        [ 0.7382, -0.9641],\n",
      "        [ 0.8219, -1.3393],\n",
      "        [ 0.8480, -1.7321],\n",
      "        [ 0.8109, -2.1370],\n",
      "        [ 0.7039, -2.5474],\n",
      "        [ 0.5187, -2.9548],\n",
      "        [ 0.1986,  0.4589],\n",
      "        [ 0.3745,  0.7710],\n",
      "        [ 0.5949,  1.0586],\n",
      "        [ 0.8585,  1.3162],\n",
      "        [ 1.1637,  1.5379],\n",
      "        [ 1.5088,  1.7169],\n",
      "        [ 1.8918,  1.8454],\n",
      "        [ 2.3103,  1.9138],\n",
      "        [ 0.3849, -0.3191],\n",
      "        [ 0.5952, -0.6168],\n",
      "        [ 0.7626, -0.9449],\n",
      "        [ 0.8827, -1.3001],\n",
      "        [ 0.9504, -1.6781],\n",
      "        [ 0.9601, -2.0743],\n",
      "        [ 0.9050, -2.4831],\n",
      "        [ 0.7768, -2.8977],\n",
      "        [-0.0529,  0.4972],\n",
      "        [ 0.0640,  0.8548],\n",
      "        [ 0.2325,  1.1918],\n",
      "        [ 0.4526,  1.5048],\n",
      "        [ 0.7238,  1.7876],\n",
      "        [ 1.0459,  2.0324],\n",
      "        [ 1.4185,  2.2299],\n",
      "        [ 1.8408,  2.3688],\n",
      "        [-0.4421,  0.2336],\n",
      "        [-0.7669,  0.3828],\n",
      "        [-1.0684,  0.5770],\n",
      "        [-1.3430,  0.8159],\n",
      "        [-1.5853,  1.0983],\n",
      "        [-1.7885,  1.4233],\n",
      "        [-1.9450,  1.7894],\n",
      "        [-2.0450,  2.1950]], device='cuda:0')\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True], device='cuda:0')\n",
      "context_mask: tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False],\n",
      "       device='cuda:0')\n",
      "target_mask: tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True,  True,  True, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False],\n",
      "       device='cuda:0')\n",
      "pids: tensor([3, 3, 3, 3, 3, 3, 3, 3, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "NaN detected in encoder output",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m wandb_logger \u001b[38;5;241m=\u001b[39m WandbLogger(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJEPA_toytrack_splitwedges\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      3\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[1;32m      4\u001b[0m     devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     logger \u001b[38;5;241m=\u001b[39m wandb_logger,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1031\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.conda/envs/jepa/lib/python3.10/site-packages/lightning/pytorch/strategies/strategy.py:412\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/dtmurnane/Side_Work/Particle-JEPA/jepa/modules/base.py:95\u001b[0m, in \u001b[0;36mBaseModule.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/dtmurnane/Side_Work/Particle-JEPA/jepa/modules/models/jepa.py:185\u001b[0m, in \u001b[0;36mJEPA.shared_evaluation\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_debug_batch_shapes(x, mask, context_mask, target_mask, pids)\n\u001b[0;32m--> 185\u001b[0m embedded_context_tracklets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_context_tracklets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m embedded_target_tracklets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_target_tracklets(x, target_mask, batch)\n\u001b[1;32m    187\u001b[0m predicted_embedded_target_tracklets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(embedded_context_tracklets)\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/dtmurnane/Side_Work/Particle-JEPA/jepa/modules/models/jepa.py:291\u001b[0m, in \u001b[0;36mJEPA._embed_context_tracklets\u001b[0;34m(self, x, mask, batch)\u001b[0m\n\u001b[1;32m    288\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x, mask)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# Add NaN check\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoder output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedded\n",
      "File \u001b[0;32m/global/cfs/cdirs/m3443/usr/dtmurnane/Side_Work/Particle-JEPA/jepa/modules/models/jepa.py:558\u001b[0m, in \u001b[0;36mJEPA._check_nan\u001b[0;34m(self, tensor, tensor_name, batch)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTensor containing NaN:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tensor)\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN detected in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: NaN detected in encoder output"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=\"JEPA_toytrack_splitwedges\")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=10, \n",
    "    devices=1, \n",
    "    accelerator=\"gpu\", \n",
    "    limit_train_batches = config[\"train_batches\"], \n",
    "    limit_val_batches = config[\"val_batches\"],\n",
    "    logger = wandb_logger,\n",
    ")\n",
    "trainer.fit(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jepa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
